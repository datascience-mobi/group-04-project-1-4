---
title: "Linear regression"
author: "Elias Benjamin Farr"
date: "17 Mai 2019"
output: tufte::tufte_handout
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Multilinear Regression
## Objective

  + For the regression model, we want to predict the CERES score of the driver mutation (dependent variable) based on the CERES score of the SST candidates (independent variables).
  + A multilinear regression will be designed:


# Step 1: Construct datasets for Regression
  + Multilinear regression, we 
    1. reform the BCCL CERES matrix
      + By transponing and format change, we obtain a matrix with colnames = Gene names and rownames = Cell line indices (equal to tPatients_ID)
    2. Collect the relevant the CERES scores for the mutations for the linear regression.
      + All columns with the corresponding names of the SST genes plus the driver mutation will be collected and copied into a new dataframe
      
```{r}
#reformat BCCL CERES matrix
BCCL_kd.ceres_df <- as.data.frame(t(BCCL_kd.ceres))
rownames(BCCL_kd.ceres_df) <- tPatients_ID
colnames(BCCL_kd.ceres_df) <- rownames(BCCL_kd.ceres)

#generate a dataframe containing data for each DV
linRegData_ERBB2 <- BCCL_kd.ceres_df %>% select(rownames(SST_Data$ERBB2), "ERBB2")
linRegData_MYCBP <- BCCL_kd.ceres_df %>% select(rownames(SST_Data$MYCBP), "MYCBP")
linRegData_PARP10 <- BCCL_kd.ceres_df %>% select(rownames(SST_Data$PARP10), "PARP10")
linRegData_PIK3CA <- BCCL_kd.ceres_df %>% select(rownames(SST_Data$PIK3CA), "PIK3CA")

data_regression <- list(linRegData_ERBB2, linRegData_MYCBP, linRegData_PARP10, linRegData_PIK3CA)
head(data_regression)
```

#Step 2: qqplot
  + Check Normality with a qqPlot
    + Using the aes-function of the ggplt package for _aesthetic_ plots.
    
```{r}
create_qqplot <- function(a){  
  p <- ggplot(data_regression[[a]], aes(sample=data_regression[[a]][,ncol(data_regression[[a]])])) + stat_qq()+ stat_qq_line()
   p + labs(title = "QQ-Plot", subtitle = "Check if data is approx. normally distributed")
}
lapply(seq_along(data_regression), create_qqplot)
```

#Step 3: Multilinear Regression: Data split, Model calculation, Return correlation data for evaluation
To run the Multilinear Regression, it is advised to create a long function which
  1. Splits the dataset in 75:25 training:test data
    + Previous installation of the "caTools" package is necessary
  2. Conducts Training of Regression model with training data
    + predict Driver mutation CERES (y; dep.variable) from SST CERES scores (x1 ... xn; indep.variables)
  3. Runs Test Data on model for performance evaluation
  4. Calculates Spearman correlation to further asess model performance
  
```{r}
input_data <- data_regression

lapply(seq_along(input_data), function(a) {
  set.seed(123) #initialize the random numbers, better reproducable
  data <- input_data[[a]] #get the data
  colnames(data)[length(colnames(data))] <- "Predictor"
  
  split = sample.split(data[,ncol(data)], SplitRatio = 0.75) #split the dataset into 3/4 Training and 1/4 Testing dataset
  training_set = subset(data, split == TRUE) #use the labels to get the training data
  test_set = subset(data, split == FALSE)

  regressor = lm(formula = Predictor ~ ., 
                 data = training_set)  #predict CERES of Driver Mutation based on all (=.) the input variables (SSTs)
  
  y_pred = predict(regressor, newdata = test_set) #predict the Driver mut. CERES score based on the test data
  test_set$Prediction = y_pred #adding predictions to the dataset
  corVal <- cor.test(test_set$Predictor , test_set$Prediction, method = "spearman")#to judge model performance, calculate Spearman corr. between predicted and observed values
  return(corVal)
})
```

## Interpretation of Spearman correlation coefficient

# Revision: Meaning of the correlation coefficient rho
  + the rank-correlation coefficient can take values from +1 to -1
    + rho ~ 1: perfect positive association of ranks
    + rho ~ 0: no association of ranks
    + rho ~ -1: perfect negative association of ranks

# Revision: Adding a statistical parameter
  + To further interprete the p-value, we construct a H0 / H1 hypothesis:
    + H0: There is no association between the predicted and observed variable.
    + H1: There is an association between the predicted and observed variable.
  + Most importantly, it is not possible to assess the strength of the correlation based on the p-value. It rather judges the statistical test than the resulting value.
    + as a standard, we set the significance level to 0.05

# Objective
 + We will the compare this values for the different models
  + For a positive correaltion, two variables move in the same direction.
    + For a well-designed model, we expect the precicted and observed CERES scores being approx. even
  + Thus, optimal model design is achieved if:
      + the correlation coefficient is close to 1
      + the p-value < 0.05
    

# Results
We obtained

Model     | p-value     | rho      | 
----------|-------------|----------|
ERBB2     | 0.8397      | 0.1071   |
MCYBP     | 0.7825      |-0.1429   |
PARP      | 0.1095      |-0.6786   |
PIK3CA    | 0.7131      |-0.1786   |

# Discussing p-Values and correlation coefficients

  + ERBB2-model:
    + Shows the highest rho value of all four models, but ~ 0.1 is a rather weak positive relationship
    + The p-value leads to __acceptance of H0__.
    + The data is not even approx. normal distributed.
    
  + MYCBP-model:
    + The rho value leads to very weak negative correlation.
    + A p-value of ~0.78 leads to condifent acceptance of H0.
    + Data is approx. normal distributed.
    
  + PARP10-model:
    + The rho value of ~ -0.67 is a moderate negative relationship.
    + The p-value leads to acceptance of H0. The p-value is the lowest with ~ 0.11. But even if we would raise the confidence level to 0.10 (which would be a questionable move in statistics), the result wouldnÂ´t be significant to accept H1.
    + Data is approx. normal distributed.
    
  + PIK3CA-model:
    + The rho value leads to very weak negative correlation.
    + A p-value of ~0.78  leads to condifent acceptance of H0.

  + __All in all, all multilinear regression models failed to deliver a p-value of significant relevance. Thus, they should not be used for further predictions.__
    + The models for MYCBP and PIK3CA only showed weak, negative correlation, which is not useful for further work with this model.
    + The PARP10 model resulted in a moderate negative relationship, which is not of relevance for our objective.
    + The ERBB2 model did not deliver a significant p-value, but indeed contains at least a weak positive correlation.

# Discussing possible Reasons for the unsatisfying results
It seems possible that the small sample size for the regression model lead to the lack of significant results, with only 28 events (CERES score observed in cell line) per predicting variable (SST gene).

But, a common thumb-rule for building a regression model is to calculate the _limiting sample size_:

 $p < \frac{m}{15}$
  + p: number of predictor variables
  + m: limiting sample size; for continuous response variables it is the  total sample size n

If this equation is fullfilled, the model is supposed to be reliable.(Harrell 2001)
In fact, this condition is true for all four models.

Furthermore, Harell describes in _Regression modeling strategies_ a strategy for optimal development of predictive models:

He points out to not use  Y (the driver mutation) any descriptive statistics or hypothesis tests in constructing the list of candidate predictors (SSTs).(Harrell 2001)
  + did we do that?
  
Also, one could delete a group of predictor variable, based on a single p-value, especially if  0.05 < p < 0.2 does not apply.(Harrell 2001)
  + Problematic is to set a random p-value to delete variables.
  + In our cases, most p-values of individual predictors were  > 0.3, where it is questionable if deleting those would be any good.
  
It was advised to check distributional assumptions (= normal distribution) and choose a different model if needed.
  + As shown in the qq-Plots, normal distribution does only apply to the models of MYCBP and PARp10
  + ERBB2 on the other hand, delivers the highest rho, but is in no way approx. normal distributed.
 
```{r}
l.g.1 = lm(ERBB2 ~ ., data = linRegData_ERBB2)
summary(l.g.1) # 7 of 17 SSTs have p > 0.5

l.g.2 = lm(MYCBP ~ ., data = linRegData_MYCBP)
summary(l.g.2) # has a good p value of 0.052, 10 of 15 SSTs have p > 0.05

l.g.3 = lm(PARP10 ~ ., data = linRegData_PARP10)
summary(l.g.3) # 4 of 17 SSTs have p > 0.5

l.g.4 = lm(PIK3CA ~ ., data = linRegData_PIK3CA)
summary(l.g.4) # 9 of 18 SSTs have p > 0.5
``` 
--------------------
Harrell, F. E. (2001). Regression modeling strategies : with applications to linear models, logistic regression, and survival analysis. New York ; Berlin ; Heidelberg [u.a.], Springer.




  